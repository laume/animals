{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition: iWildCam 2019 - FGVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the environment and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/moon/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18041535734319365496\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14032058403384056406\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2679640303256351274\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14938520606972592935\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U dlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U toai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iwildcam-2019-fgvc6.zip  pictures\r\n"
     ]
    }
   ],
   "source": [
    "!ls a_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c iwildcam-2019-fgvc6 -p a_pic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip a_data/iwildcam-2019-fgvc6.zip -d a_data/pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv\t\ttrain.csv\r\n",
      "test\t\t       test_images.zip\ttrain_images.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls a_pic/pictures/iwildcam-2019-fgvc6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59c17a18-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "5a2963b2-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "58f8ce52-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "59d419ed-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "59ddc012-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls -U {DATA_DIR} | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toai.imports import *\n",
    "from toai.data import Dataset, DataParams, DataContainer, split_df\n",
    "from toai.models import save_keras_model, load_keras_model\n",
    "from toai.metrics import sparse_top_2_categorical_accuracy\n",
    "from toai.image import (\n",
    "    ImageLearner,\n",
    "    ImageAugmentor,\n",
    "    ImageDataset,\n",
    "    ImageParser,\n",
    "    ImageResizer,\n",
    "    LearningRateFinder,\n",
    "    ImageTrainingStep,\n",
    "    ImageTrainer,\n",
    ")\n",
    "from toai.utils import download_file, unzip, save_file, load_file\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"a_pic/pictures/iwildcam-2019-fgvc6/train/train_images\")\n",
    "TEMP_DIR = Path(\"temp/scenes\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('a_pic/pictures/iwildcam-2019-fgvc6/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>category_id</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>date_captured</td>\n",
       "      <td>2011-05-13 23:43:18</td>\n",
       "      <td>2012-03-17 03:48:44</td>\n",
       "      <td>2014-05-11 11:56:46</td>\n",
       "      <td>2013-10-06 02:00:00</td>\n",
       "      <td>2011-07-12 13:11:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>file_name</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>frame_num</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>id</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>location</td>\n",
       "      <td>33</td>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>57</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rights_holder</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>Justin Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seq_id</td>\n",
       "      <td>6f084ccc-5567-11e8-bc84-dca9047ef277</td>\n",
       "      <td>6f12067d-5567-11e8-b3c0-dca9047ef277</td>\n",
       "      <td>6faa92d1-5567-11e8-b1ae-dca9047ef277</td>\n",
       "      <td>6f7d4702-5567-11e8-9e03-dca9047ef277</td>\n",
       "      <td>6f1728a1-5567-11e8-9be7-dca9047ef277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seq_num_frames</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>width</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>height</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "category_id                                           19   \n",
       "date_captured                        2011-05-13 23:43:18   \n",
       "file_name       5998cfa4-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "frame_num                                              1   \n",
       "id                  5998cfa4-23d2-11e8-a6a3-ec086b02610b   \n",
       "location                                              33   \n",
       "rights_holder                               Justin Brown   \n",
       "seq_id              6f084ccc-5567-11e8-bc84-dca9047ef277   \n",
       "seq_num_frames                                         3   \n",
       "width                                               1024   \n",
       "height                                               747   \n",
       "\n",
       "                                                       1  \\\n",
       "category_id                                           19   \n",
       "date_captured                        2012-03-17 03:48:44   \n",
       "file_name       588a679f-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "frame_num                                              2   \n",
       "id                  588a679f-23d2-11e8-a6a3-ec086b02610b   \n",
       "location                                             115   \n",
       "rights_holder                               Justin Brown   \n",
       "seq_id              6f12067d-5567-11e8-b3c0-dca9047ef277   \n",
       "seq_num_frames                                         3   \n",
       "width                                               1024   \n",
       "height                                               747   \n",
       "\n",
       "                                                       2  \\\n",
       "category_id                                            0   \n",
       "date_captured                        2014-05-11 11:56:46   \n",
       "file_name       59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "frame_num                                              1   \n",
       "id                  59279ce3-23d2-11e8-a6a3-ec086b02610b   \n",
       "location                                              96   \n",
       "rights_holder                              Erin Boydston   \n",
       "seq_id              6faa92d1-5567-11e8-b1ae-dca9047ef277   \n",
       "seq_num_frames                                         1   \n",
       "width                                               1024   \n",
       "height                                               747   \n",
       "\n",
       "                                                       3  \\\n",
       "category_id                                            0   \n",
       "date_captured                        2013-10-06 02:00:00   \n",
       "file_name       5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "frame_num                                              1   \n",
       "id                  5a2af4ab-23d2-11e8-a6a3-ec086b02610b   \n",
       "location                                              57   \n",
       "rights_holder                              Erin Boydston   \n",
       "seq_id              6f7d4702-5567-11e8-9e03-dca9047ef277   \n",
       "seq_num_frames                                         1   \n",
       "width                                               1024   \n",
       "height                                               747   \n",
       "\n",
       "                                                       4  \n",
       "category_id                                            0  \n",
       "date_captured                        2011-07-12 13:11:16  \n",
       "file_name       599fbd89-23d2-11e8-a6a3-ec086b02610b.jpg  \n",
       "frame_num                                              3  \n",
       "id                  599fbd89-23d2-11e8-a6a3-ec086b02610b  \n",
       "location                                              46  \n",
       "rights_holder                               Justin Brown  \n",
       "seq_id              6f1728a1-5567-11e8-9be7-dca9047ef277  \n",
       "seq_num_frames                                         3  \n",
       "width                                               1024  \n",
       "height                                               747  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in train.iterrows():\n",
    "    for_val = DATA_DIR/value[2]\n",
    "    train.at[index,'file_name'] = for_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>rights_holder</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_num_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2011-05-13 23:43:18</td>\n",
       "      <td>a_pic/pictures/iwildcam-2019-fgvc6/train/train...</td>\n",
       "      <td>1</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>33</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f084ccc-5567-11e8-bc84-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2012-03-17 03:48:44</td>\n",
       "      <td>a_pic/pictures/iwildcam-2019-fgvc6/train/train...</td>\n",
       "      <td>2</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>115</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f12067d-5567-11e8-b3c0-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-11 11:56:46</td>\n",
       "      <td>a_pic/pictures/iwildcam-2019-fgvc6/train/train...</td>\n",
       "      <td>1</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>96</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6faa92d1-5567-11e8-b1ae-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06 02:00:00</td>\n",
       "      <td>a_pic/pictures/iwildcam-2019-fgvc6/train/train...</td>\n",
       "      <td>1</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>57</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6f7d4702-5567-11e8-9e03-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-12 13:11:16</td>\n",
       "      <td>a_pic/pictures/iwildcam-2019-fgvc6/train/train...</td>\n",
       "      <td>3</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>46</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f1728a1-5567-11e8-9be7-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id        date_captured  \\\n",
       "0           19  2011-05-13 23:43:18   \n",
       "1           19  2012-03-17 03:48:44   \n",
       "2            0  2014-05-11 11:56:46   \n",
       "3            0  2013-10-06 02:00:00   \n",
       "4            0  2011-07-12 13:11:16   \n",
       "\n",
       "                                           file_name  frame_num  \\\n",
       "0  a_pic/pictures/iwildcam-2019-fgvc6/train/train...          1   \n",
       "1  a_pic/pictures/iwildcam-2019-fgvc6/train/train...          2   \n",
       "2  a_pic/pictures/iwildcam-2019-fgvc6/train/train...          1   \n",
       "3  a_pic/pictures/iwildcam-2019-fgvc6/train/train...          1   \n",
       "4  a_pic/pictures/iwildcam-2019-fgvc6/train/train...          3   \n",
       "\n",
       "                                     id  location  rights_holder  \\\n",
       "0  5998cfa4-23d2-11e8-a6a3-ec086b02610b        33   Justin Brown   \n",
       "1  588a679f-23d2-11e8-a6a3-ec086b02610b       115   Justin Brown   \n",
       "2  59279ce3-23d2-11e8-a6a3-ec086b02610b        96  Erin Boydston   \n",
       "3  5a2af4ab-23d2-11e8-a6a3-ec086b02610b        57  Erin Boydston   \n",
       "4  599fbd89-23d2-11e8-a6a3-ec086b02610b        46   Justin Brown   \n",
       "\n",
       "                                 seq_id  seq_num_frames  width  height  \n",
       "0  6f084ccc-5567-11e8-bc84-dca9047ef277               3   1024     747  \n",
       "1  6f12067d-5567-11e8-b3c0-dca9047ef277               3   1024     747  \n",
       "2  6faa92d1-5567-11e8-b1ae-dca9047ef277               1   1024     747  \n",
       "3  6f7d4702-5567-11e8-9e03-dca9047ef277               1   1024     747  \n",
       "4  6f1728a1-5567-11e8-9be7-dca9047ef277               3   1024     747  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     131457\n",
       "19     14106\n",
       "13      8623\n",
       "11      7209\n",
       "8       6938\n",
       "1       6102\n",
       "16      5975\n",
       "17      4759\n",
       "3       3398\n",
       "18      3035\n",
       "4       2210\n",
       "14      1361\n",
       "10      1093\n",
       "22        33\n",
       "Name: category_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.category_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196299"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196299 entries, 0 to 196298\n",
      "Data columns (total 11 columns):\n",
      "category_id       196299 non-null int64\n",
      "date_captured     196299 non-null object\n",
      "file_name         196299 non-null object\n",
      "frame_num         196299 non-null int64\n",
      "id                196299 non-null object\n",
      "location          196299 non-null int64\n",
      "rights_holder     196299 non-null object\n",
      "seq_id            196299 non-null object\n",
      "seq_num_frames    196299 non-null int64\n",
      "width             196299 non-null int64\n",
      "height            196299 non-null int64\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>196299.0</td>\n",
       "      <td>196299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.128948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          width         height\n",
       "count  196299.0  196299.000000\n",
       "mean     1024.0     747.486600\n",
       "std         0.0       3.128948\n",
       "min      1024.0     747.000000\n",
       "25%      1024.0     747.000000\n",
       "50%      1024.0     747.000000\n",
       "75%      1024.0     747.000000\n",
       "max      1024.0     768.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['width', 'height']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747    189960\n",
       "768      4459\n",
       "748      1880\n",
       "Name: height, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.height.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('width').height.value_counts().unstack(0).plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('a_pic/pictures/iwildcam-2019-fgvc6/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>date_captured</td>\n",
       "      <td>2016-01-03 11:30:56</td>\n",
       "      <td>2016-01-03 11:30:57</td>\n",
       "      <td>2016-01-03 11:30:58</td>\n",
       "      <td>2016-01-03 11:30:59</td>\n",
       "      <td>2016-01-03 11:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>file_name</td>\n",
       "      <td>bce932f6-2bf6-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>bce932f7-2bf6-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>bce932f8-2bf6-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>bce932f9-2bf6-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>bce932fa-2bf6-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>frame_num</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>id</td>\n",
       "      <td>bce932f6-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>bce932f7-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>bce932f8-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>bce932f9-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>bce932fa-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>location</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rights_holder</td>\n",
       "      <td>Idaho Department of Fish and Game</td>\n",
       "      <td>Idaho Department of Fish and Game</td>\n",
       "      <td>Idaho Department of Fish and Game</td>\n",
       "      <td>Idaho Department of Fish and Game</td>\n",
       "      <td>Idaho Department of Fish and Game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seq_id</td>\n",
       "      <td>6e9ac61c-2e32-11e9-90ef-dca9047ef277</td>\n",
       "      <td>6e9ac61c-2e32-11e9-90ef-dca9047ef277</td>\n",
       "      <td>6e9ac61c-2e32-11e9-90ef-dca9047ef277</td>\n",
       "      <td>6e9ac61c-2e32-11e9-90ef-dca9047ef277</td>\n",
       "      <td>6e9ac61c-2e32-11e9-90ef-dca9047ef277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seq_num_frames</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>width</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>height</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "date_captured                        2016-01-03 11:30:56   \n",
       "file_name       bce932f6-2bf6-11e9-bcad-06f10d5896c4.jpg   \n",
       "frame_num                                              1   \n",
       "id                  bce932f6-2bf6-11e9-bcad-06f10d5896c4   \n",
       "location                                              37   \n",
       "rights_holder          Idaho Department of Fish and Game   \n",
       "seq_id              6e9ac61c-2e32-11e9-90ef-dca9047ef277   \n",
       "seq_num_frames                                         5   \n",
       "width                                               1024   \n",
       "height                                               726   \n",
       "\n",
       "                                                       1  \\\n",
       "date_captured                        2016-01-03 11:30:57   \n",
       "file_name       bce932f7-2bf6-11e9-bcad-06f10d5896c4.jpg   \n",
       "frame_num                                              2   \n",
       "id                  bce932f7-2bf6-11e9-bcad-06f10d5896c4   \n",
       "location                                              37   \n",
       "rights_holder          Idaho Department of Fish and Game   \n",
       "seq_id              6e9ac61c-2e32-11e9-90ef-dca9047ef277   \n",
       "seq_num_frames                                         5   \n",
       "width                                               1024   \n",
       "height                                               726   \n",
       "\n",
       "                                                       2  \\\n",
       "date_captured                        2016-01-03 11:30:58   \n",
       "file_name       bce932f8-2bf6-11e9-bcad-06f10d5896c4.jpg   \n",
       "frame_num                                              3   \n",
       "id                  bce932f8-2bf6-11e9-bcad-06f10d5896c4   \n",
       "location                                              37   \n",
       "rights_holder          Idaho Department of Fish and Game   \n",
       "seq_id              6e9ac61c-2e32-11e9-90ef-dca9047ef277   \n",
       "seq_num_frames                                         5   \n",
       "width                                               1024   \n",
       "height                                               726   \n",
       "\n",
       "                                                       3  \\\n",
       "date_captured                        2016-01-03 11:30:59   \n",
       "file_name       bce932f9-2bf6-11e9-bcad-06f10d5896c4.jpg   \n",
       "frame_num                                              4   \n",
       "id                  bce932f9-2bf6-11e9-bcad-06f10d5896c4   \n",
       "location                                              37   \n",
       "rights_holder          Idaho Department of Fish and Game   \n",
       "seq_id              6e9ac61c-2e32-11e9-90ef-dca9047ef277   \n",
       "seq_num_frames                                         5   \n",
       "width                                               1024   \n",
       "height                                               726   \n",
       "\n",
       "                                                       4  \n",
       "date_captured                        2016-01-03 11:31:00  \n",
       "file_name       bce932fa-2bf6-11e9-bcad-06f10d5896c4.jpg  \n",
       "frame_num                                              5  \n",
       "id                  bce932fa-2bf6-11e9-bcad-06f10d5896c4  \n",
       "location                                              37  \n",
       "rights_holder          Idaho Department of Fish and Game  \n",
       "seq_id              6e9ac61c-2e32-11e9-90ef-dca9047ef277  \n",
       "seq_num_frames                                         5  \n",
       "width                                               1024  \n",
       "height                                               726  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As test dataset don't have labels I will do training and validation only on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = ImageDataset.split(\n",
    "    dataset=ImageDataset.from_dataframe(train, 'file_name', 'category_id'),\n",
    "    fracs=(0.8, 0.1, 0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIMS = 100, 100, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type PosixPath).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-538dc3f2cd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         ],\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0msave_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMP_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/toai/image/ImageDataset.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mimage_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mimage_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_with_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    433\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 111\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    112\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/lu_lab/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type PosixPath)."
     ]
    }
   ],
   "source": [
    "train_image_dataset = (\n",
    "    train_data\n",
    "    .dataset(batch_size=32, img_dims=IMG_DIMS, shuffle=True)\n",
    "    .make_pipeline(\n",
    "        image_pipeline=[\n",
    "            ImageParser(),\n",
    "            ImageResizer(img_dims=IMG_DIMS, resize=\"stretch\"),\n",
    "            ImageAugmentor(level=3, flips=\"both\"),\n",
    "        ],\n",
    "    )\n",
    "    .save_pipeline(TEMP_DIR/\"train\")\n",
    "    .preprocess()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
